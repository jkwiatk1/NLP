{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3U0hq1Lt2qD",
        "outputId": "b3e47275-948f-43b9-ca2f-5052f8ec4ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "\n",
        "root = '/content/drive/My Drive/NLP'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn-Hg1y1xmlT",
        "outputId": "a1d95e9b-6c98-4166-83db-5c4b25beacb7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 31 20:29:48 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0    29W /  70W |   1919MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "sts_path = os.path.join(root, 'stsb/')\n",
        "print(sts_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qj3zRqSxoAP",
        "outputId": "a5d55bfe-cba6-4635-bcf9-cff6f4bdf6cc"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/NLP/stsb/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers==4.25.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV5Dmp3dxp40",
        "outputId": "07e27bb2-3590-488d-b73b-8db4e2e51b58"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.25.1 in /usr/local/lib/python3.10/dist-packages (4.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoModelForMaskedLM\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup,get_cosine_schedule_with_warmup\n",
        "from transformers import get_cosine_with_hard_restarts_schedule_with_warmup\n",
        "from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup, RobertaConfig\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "from ipywidgets import IntProgress\n",
        "import time"
      ],
      "metadata": {
        "id": "MUG_vWMix5lm"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and set device to GPU.\n",
        "torch.manual_seed(17)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rGUidVtySVw",
        "outputId": "b331ed4f-9daf-4367-b180-678095d02cb9"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_WORKERS = 0\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "EPOCHS = 12\n",
        "SEED = 2023\n",
        "LR = 1e-5\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "transformer_model = 'roberta-base'\n",
        "TOKENIZER = RobertaTokenizer.from_pretrained(transformer_model)\n",
        "CONFIG = RobertaConfig.from_pretrained(transformer_model)\n",
        "\n",
        "mask_tok = 50264"
      ],
      "metadata": {
        "id": "hk_0PW1vUSpU"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    \n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "    \n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "wD1Q-QSxWIXb"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_metrics(path, train_loss_list, valid_loss_list, global_steps_list):   \n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "    torch.save(state_dict, path)\n",
        "\n",
        "def load_metrics(path):    \n",
        "    state_dict = torch.load(path, map_location=device)\n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
      ],
      "metadata": {
        "id": "gXs-lZbpnVW5"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, path):\n",
        "    torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "xFtyQD1aoplO"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from https://www.kaggle.com/code/tanulsingh077/masked-token-pretraining-xlm-roberta/notebook\n",
        "class Data(Dataset):\n",
        "    def __init__(self, csv):\n",
        "        self.csv = csv.reset_index()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.csv.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.csv.iloc[index]\n",
        "        text = row.text\n",
        "        \n",
        "        text = TOKENIZER(text,\n",
        "                         return_attention_mask=False,\n",
        "                         return_token_type_ids=False,\n",
        "                         padding='max_length',\n",
        "                         truncation=True,\n",
        "                         max_length=64)\n",
        "        \n",
        "        input_ids = text['input_ids']\n",
        "        \n",
        "        input_ids,labels = self.prepare_mlm_input_and_labels(np.array(input_ids))\n",
        "\n",
        "        input_ids = torch.tensor(input_ids,dtype=torch.long)\n",
        "        labels = torch.tensor(labels,dtype=torch.long)\n",
        "    \n",
        "        return input_ids,labels\n",
        "    \n",
        "    def prepare_mlm_input_and_labels(self,X):\n",
        "        # 15% BERT masking\n",
        "        inp_mask = np.random.rand(*X.shape)<0.15 \n",
        "        # do not mask special tokens\n",
        "        inp_mask[X<=2] = False\n",
        "        # set targets to -1 by default, it means ignore\n",
        "        labels = -100 * np.ones(X.shape, dtype=int)\n",
        "        # set labels for masked tokens\n",
        "        labels[inp_mask] = X[inp_mask]\n",
        "        \n",
        "        # prepare input\n",
        "        X_mlm = np.copy(X)\n",
        "        # set input to [MASK] which is the last token for the 90% of tokens\n",
        "        # this means leaving 10% unchanged\n",
        "        inp_mask_2mask = inp_mask  & (np.random.rand(*X.shape)<0.90)\n",
        "        X_mlm[inp_mask_2mask] = mask_tok\n",
        "\n",
        "        # set 10% to a random token\n",
        "        inp_mask_2random = inp_mask_2mask  & (np.random.rand(*X.shape) < 1/9)\n",
        "        X_mlm[inp_mask_2random] = np.random.randint(3, CONFIG.vocab_size, inp_mask_2random.sum())\n",
        "\n",
        "        return X_mlm, labels"
      ],
      "metadata": {
        "id": "GJWQdwRKWawe"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from decimal import Decimal\n",
        "# Load CSV file with dataset. Perform basic transformations.\n",
        "df_train = pd.read_csv(sts_path+'/stsb-en-train.csv', delimiter=',', header= None, names = ['s1','s2','target'])\n",
        "df_valid = pd.read_csv(sts_path+'/stsb-en-dev.csv', delimiter=',', header= None, names = ['s1','s2','target'])\n",
        "df_test = pd.read_csv(sts_path+'/stsb-en-test.csv', delimiter=',', header= None, names = ['s1','s2','target'])\n",
        "\n",
        "def process_sts(df_data):\n",
        "  df_data['text'] = df_data['s1'] + df_data['s2']\n",
        "  df_data = df_data[['text', 'target']].copy()\n",
        "  df_data['target'] = df_data['target'].map(lambda x: int(Decimal(x).to_integral_value()))\n",
        "  return df_data\n",
        "\n",
        "df_train = process_sts(df_train)\n",
        "df_valid = process_sts(df_valid)\n",
        "df_test = process_sts(df_test)"
      ],
      "metadata": {
        "id": "T5n6gs3ofjnw"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.reset_index(drop=True)\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "df_valid = df_valid.reset_index(drop=True)\n",
        "\n",
        "df_train = pd.concat([df_train, df_test, df_valid])\n",
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lilje0JEu864",
        "outputId": "ef6238d6-932e-4634-8152-0eac647dfc97"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  target\n",
              "0     A plane is taking off.An air plane is taking off.       5\n",
              "1     A man is playing a large flute.A man is playin...       4\n",
              "2     A man is spreading shreded cheese on a pizza.A...       4\n",
              "3     Three men are playing chess.Two men are playin...       3\n",
              "4     A man is playing the cello.A man seated is pla...       4\n",
              "...                                                 ...     ...\n",
              "1495  Scientists prove there is water on MarsHas Nas...       2\n",
              "1496  Pranab stresses need to strive for peace by na...       0\n",
              "1497  Volkswagen skids into red in wake of pollution...       2\n",
              "1498  Obama is right: Africa deserves better leaders...       0\n",
              "1499  New video shows US police officers beating men...       0\n",
              "\n",
              "[8628 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0c88868-2d51-4de2-aa4d-4d2697e70ce6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A plane is taking off.An air plane is taking off.</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A man is playing a large flute.A man is playin...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A man is spreading shreded cheese on a pizza.A...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Three men are playing chess.Two men are playin...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A man is playing the cello.A man seated is pla...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>Scientists prove there is water on MarsHas Nas...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>Pranab stresses need to strive for peace by na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>Volkswagen skids into red in wake of pollution...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>Obama is right: Africa deserves better leaders...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>New video shows US police officers beating men...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8628 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0c88868-2d51-4de2-aa4d-4d2697e70ce6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0c88868-2d51-4de2-aa4d-4d2697e70ce6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0c88868-2d51-4de2-aa4d-4d2697e70ce6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_value_counts = pd.DataFrame(df_train['target']).value_counts(sort=False)\n",
        "    # odwrotne wagowanie klas\n",
        "weights = ((1/class_value_counts.values) / np.sum(1/class_value_counts.values ))\n",
        "print(weights)\n",
        "class_weights = torch.FloatTensor(weights).cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er9UhuesfL-m",
        "outputId": "a2b96bba-0c18-4f98-d82a-4d6420630b08"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.20891525 0.1764098  0.14971781 0.11152136 0.10521493 0.24822086]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_categorical_crossentropy(output,target):\n",
        "    y_true_masked = target[target!= -100]\n",
        "    y_pred_masked = output[target!= -100]\n",
        "    loss =  torch.nn.CrossEntropyLoss(weight=class_weights)(y_pred_masked,y_true_masked)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "XB6xIWF-WfOp"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(dataloader,model,optimizer,device,scheduler,epoch):\n",
        "    model.train()\n",
        "    loss_score = AverageMeter()\n",
        "    \n",
        "    tk0 = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for bi,d in tk0:\n",
        "        \n",
        "        batch_size = d[0].shape[0]\n",
        "\n",
        "        input_ids = d[0]\n",
        "        targets = d[1]\n",
        "\n",
        "        input_ids = input_ids.to(device,dtype=torch.long)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(input_ids=input_ids,labels=targets)\n",
        "        \n",
        "        loss = output.loss       \n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss_score.update(loss.detach().item(), batch_size)\n",
        "        tk0.set_postfix(Train_Loss=loss_score.avg,Epoch=epoch,LR=optimizer.param_groups[0]['lr'])\n",
        "        \n",
        "        if scheduler is not None:\n",
        "                scheduler.step()\n",
        "        \n",
        "    return loss_score"
      ],
      "metadata": {
        "id": "zJjTHZ7pWjm_"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "    train_dataset = Data(\n",
        "        csv=df_train\n",
        "    )\n",
        "        \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=TRAIN_BATCH_SIZE,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        num_workers=NUM_WORKERS\n",
        "    )\n",
        "    \n",
        "    \n",
        "    model = RobertaForMaskedLM.from_pretrained(transformer_model)\n",
        "    model.to(device)\n",
        "\n",
        "        \n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0001},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
        "            ]  \n",
        "    \n",
        "    optimizer = AdamW(optimizer_parameters, lr=LR)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps=len(train_loader)*5, \n",
        "        num_training_steps=len(train_loader)*EPOCHS\n",
        "    )\n",
        "        \n",
        "    # THE ENGINE LOOP\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss = train_fn(train_loader, model,optimizer, device,scheduler=scheduler,epoch=epoch)\n",
        "\n",
        "\n",
        "    model.save_pretrained(root+'/roberta_unsp_base')\n",
        "    save_model(model, root + '/roberta_unsp_classifier')"
      ],
      "metadata": {
        "id": "EkdiGbV1WpVU"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xm2j6lyycq-",
        "outputId": "645df905-89be-4aee-ea56-f932d47e952b"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "100%|██████████| 269/269 [02:17<00:00,  1.96it/s, Epoch=0, LR=1.99e-6, Train_Loss=2.43]\n",
            "100%|██████████| 269/269 [02:15<00:00,  1.99it/s, Epoch=1, LR=3.99e-6, Train_Loss=1.66]\n",
            "100%|██████████| 269/269 [02:15<00:00,  1.99it/s, Epoch=2, LR=5.99e-6, Train_Loss=1.51]\n",
            "100%|██████████| 269/269 [02:15<00:00,  1.98it/s, Epoch=3, LR=7.99e-6, Train_Loss=1.42]\n",
            "100%|██████████| 269/269 [02:16<00:00,  1.97it/s, Epoch=4, LR=9.99e-6, Train_Loss=1.41]\n",
            "100%|██████████| 269/269 [02:15<00:00,  1.98it/s, Epoch=5, LR=8.58e-6, Train_Loss=1.34]\n",
            "100%|██████████| 269/269 [02:15<00:00,  1.98it/s, Epoch=6, LR=7.15e-6, Train_Loss=1.35]\n",
            "100%|██████████| 269/269 [02:15<00:00,  1.98it/s, Epoch=7, LR=5.72e-6, Train_Loss=1.31]\n",
            "100%|██████████| 269/269 [02:15<00:00,  1.99it/s, Epoch=8, LR=4.29e-6, Train_Loss=1.27]\n",
            "100%|██████████| 269/269 [02:15<00:00,  1.98it/s, Epoch=9, LR=2.86e-6, Train_Loss=1.29]\n",
            "100%|██████████| 269/269 [02:15<00:00,  1.98it/s, Epoch=10, LR=1.43e-6, Train_Loss=1.23]\n",
            "100%|██████████| 269/269 [02:15<00:00,  1.98it/s, Epoch=11, LR=5.31e-9, Train_Loss=1.2]\n"
          ]
        }
      ]
    }
  ]
}